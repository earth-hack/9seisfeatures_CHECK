{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from numpy import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the seismic image which has been converted into ASCII format\n",
    "\n",
    "input_path = '...'\n",
    "\n",
    "Data=np.genfromtxt(input_path + \".../97_09_01_curv3d_mostpos_il_data.ascii\",delimiter ='')\n",
    "Labeld=np.genfromtxt(input_path + \".../97_09_01_curv3d_mostpos_il_fault.ascii\",delimiter ='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting Subline, Crossline, Time, Amplitude (data in ascii)\n",
    "\n",
    "Subline = Data[1:,0:1]\n",
    "Crossline = Data[1:,1:2]\n",
    "Time = Data[1:,2:3]\n",
    "Amp = Data[1:,3:4]\n",
    "Label = Labeld[1:,3:4]\n",
    "\n",
    "print(len(Subline),len(Crossline),len(Time),len(Amp))\n",
    "print(len(Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting only one subline\n",
    "\n",
    "xline=4000\n",
    "times=351\n",
    "subline=9\n",
    "A=Amp[(subline-1)*xline*times:subline*xline*times,:]\n",
    "\n",
    "print(A.shape)\n",
    "\n",
    "t=1\n",
    "a=np.ones((times,1))\n",
    "print(a.shape)\n",
    "for i in range(xline):\n",
    "    b=0\n",
    "    temp=A[i*times:t*times,0*t:1*t]\n",
    "    b=t*20\n",
    "    t=t+1\n",
    "    a=np.c_[a,temp]\n",
    "\n",
    "a=a[:,1:4001]\n",
    "\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "A=a*255\n",
    "A=Image.fromarray(A)\n",
    "A.show()\n",
    "\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "\n",
    "\n",
    "L=Label[(subline-1)*xline*times:subline*xline*times,:]\n",
    "\n",
    "print(L.shape)\n",
    "\n",
    "t=1\n",
    "a=np.ones((times,1))\n",
    "print(a.shape)\n",
    "for i in range(xline):\n",
    "    b=0\n",
    "    temp=L[i*times:t*times,0*t:1*t]\n",
    "    b=t*20\n",
    "    t=t+1\n",
    "    a=np.c_[a,temp]\n",
    "\n",
    "a=a[:,1:4001]\n",
    "print(a.shape)\n",
    "\n",
    "L=a*255\n",
    "L=Image.fromarray(L)\n",
    "L.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sliding window to crop to arrange the dataset in array form\n",
    "\n",
    "L1=L.crop((2170,50,3311,275))\n",
    "L1.show()\n",
    "A1=A.crop((2170,50,3311,275))\n",
    "A1.show()\n",
    "\n",
    "subline1=np.asarray(A1)\n",
    "h,w=subline1.shape\n",
    "Label1=np.asarray(L1)\n",
    "\n",
    "# Fault=np.ones((40,40))\n",
    "# No_Fault=np.ones((40,40))\n",
    "# img_id=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export the crop image into folders in computer\n",
    "\n",
    "t=10\n",
    "t2=3\n",
    "\n",
    "h1=0\n",
    "h2=40\n",
    "run2=True\n",
    "while run2==True:\n",
    "    w1=0\n",
    "    w2=40\n",
    "    print(h1,h2,w1,w2)\n",
    "    run1=True\n",
    "    while run1==True:\n",
    "        label_sw=Label1[h1:h2,w1:w2]\n",
    "        data=subline1[h1:h2,w1:w2]\n",
    "        img=Image.fromarray(data)\n",
    "        img=img.convert('L')\n",
    "        if np.sum(label_sw)>=t:\n",
    "            img_id+=1\n",
    "            Fault=np.dstack((Fault,data))\n",
    "            img.save('/Users/rewathi/Desktop/CHECK_data/sublines_ascii/fault/'+str(img_id)+'.png')\n",
    "        elif np.sum(label_sw)<t2:\n",
    "            img_id+=1\n",
    "            No_Fault=np.dstack((No_Fault,data))\n",
    "            img.save('/Users/rewathi/Desktop/CHECK_data/sublines_ascii/no_fault/'+str(img_id)+'.png')\n",
    "        \n",
    "        w1+=10\n",
    "        w2+=10\n",
    "        if w2>w:\n",
    "            data=subline1[h1:h2,w-40:w]\n",
    "            img=Image.fromarray(data)\n",
    "            img=img.convert('L')\n",
    "            if np.sum(label_sw)>=t:\n",
    "                Fault=np.dstack((Fault,data))\n",
    "                img_id+=1\n",
    "                img.save('/Users/rewathi/Desktop/CHECK_data/sublines_ascii/fault/'+str(img_id)+'.png')\n",
    "                break\n",
    "            elif np.sum(label_sw)<t2:\n",
    "                img.save('/Users/rewathi/Desktop/CHECK_data/sublines_ascii/no_fault/'+str(img_id)+'.png')\n",
    "                No_Fault=np.dstack((No_Fault,data))\n",
    "                img_id+=1\n",
    "                break\n",
    "    h1+=10\n",
    "    h2+=10\n",
    "    if h2>h :\n",
    "        if w2<w:\n",
    "            data=subline1[h-40:h,w1:w2]\n",
    "        else:\n",
    "            data=subline1[h-40:h,w-40:w]\n",
    "        img=Image.fromarray(data)\n",
    "        img=img.convert('L')\n",
    "        if np.sum(label_sw)>=t:\n",
    "            img.save('/Users/rewathi/Desktop/CHECK_data/sublines_ascii/fault/'+str(img_id)+'.png')\n",
    "            Fault=np.dstack((Fault,data))\n",
    "            img_id+=1\n",
    "            break\n",
    "        elif np.sum(label_sw)<t2:\n",
    "            img.save('/Users/rewathi/Desktop/CHECK_data/sublines_ascii/no_fault/'+str(img_id)+'.png')\n",
    "            No_Fault=np.dstack((No_Fault,data))\n",
    "            img_id+=1\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose the data to generate more training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 40, 2703)\n",
      "(2703, 40, 40)\n",
      "(19554, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "print(Fault.shape)\n",
    "Fault_T=np.transpose(Fault,(2,0,1))\n",
    "No_Fault_T=np.transpose(No_Fault,(2,0,1))\n",
    "print(Fault_T.shape)\n",
    "print(No_Fault_T.shape)\n",
    "# print(Fault_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fault_data=Fault_T[1:,:]\n",
    "No_Fault_data=No_Fault_T[1:,:]\n",
    "Fault_data.tofile('/Users/rewathi/Desktop/CHECK_data/sublines_ascii/Total_Fault__train1.txt',sep=\",\",format=\"%s\")\n",
    "No_Fault_data.tofile('/Users/rewathi/Desktop/CHECK_data/sublines_ascii/Total_NoFault_train1.txt',sep=\",\",format=\"%s\")\n",
    "# # np.savetxt('Total_Fault.txt',No_Fault)\n",
    "# # np.savetxt('No_Fault.txt',No_Fault)\n",
    "# print(Fault.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2702, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "# # Fault_train=np.genfromtxt(\"/Users/rewathi/Desktop/Hackathon/Img/subline_seis/Total_Fault_1.txt\",delimiter =',')\n",
    "# No_Fault_train=np.genfromtxt(\"/Users/rewathi/Desktop/Hackathon/Img/subline_seis/Total_NoFault_1.txt\",delimiter =',')\n",
    "# Fault=Fault_train.reshape((1787,40,40))\n",
    "print(Fault_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2702, 40, 40)\n",
      "(5404, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "#making training dataset\n",
    "TrainF=Fault_data[:2702,:]\n",
    "TrainNF=No_Fault_data[:2702,:]\n",
    "print(TrainNF.shape)\n",
    "Train=np.r_[(TrainF,TrainNF)]\n",
    "Train.tofile('/Users/rewathi/Desktop/CHECK_data/sublines_ascii/Train1.txt',sep=\",\",format=\"%s\")\n",
    "print(Train.shape)\n",
    "Labeltrain1=np.ones((2702))\n",
    "Labeltrain2=np.zeros((2702))\n",
    "Labeltrain=np.r_[(Labeltrain1,Labeltrain2)]\n",
    "np.savetxt('/Users/rewathi/Desktop/CHECK_data/sublines_ascii/Train1_Label.txt',Labeltrain,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "TestF=Fault[855:1055,:]\n",
    "TestNF=No_Fault[855:1055,:]\n",
    "Test=np.r_[(TestF,TestNF)]\n",
    "print(Test.shape)\n",
    "Test.tofile('Test.txt',sep=\",\",format=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labeltest1=np.ones((200))\n",
    "Labeltest2=np.zeros((200))\n",
    "Labeltest=np.r_[(Labeltest1,Labeltest2)]\n",
    "np.savetxt('Test_Label.txt',Labeltest,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read into train and test dataset for modelling\n",
    "input_path = '...'\n",
    "\n",
    "## Train data\n",
    "x_train = np.genfromtxt(input_path +  \".../XL_train1.txt\", delimiter = ',')\n",
    "y_train = np.genfromtxt(input_path +  \".../XL_train1_Label.txt\", delimiter = ',')\n",
    "\n",
    "## Test data\n",
    "x_test = np.genfromtxt(input_path +  \".../Test_train1.txt\", delimiter = ',')\n",
    "y_test = np.genfromtxt(input_path +  \".../Test_train1_Label.txt\", delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape the data for input into modelling\n",
    "\n",
    "x_train = (x_train/255).reshape(4712, 40, 40)\n",
    "y_train = y_train\n",
    "x_test = (x_test/255).reshape(714, 40, 40)\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline modelling\n",
    "\n",
    "#network structure\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(40, 40)),\n",
    "    tf.keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(400, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modelling\n",
    "baseline_model = model.fit(x_train_3d, y_train_3d, epochs=500, validation_data=(x_test_3d, y_test_3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the model accuracy and loss function\n",
    "\n",
    "fig = plt.figure(figsize = (20,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(baseline_model.history['acc'])\n",
    "plt.plot(baseline_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(baseline_model.history['loss'])\n",
    "plt.plot(baseline_model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
